# -*- coding: utf-8 -*-
"""200260034_EE782_A1

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1sZ_BKHpGHnwm3KwvTc5y_gLHYY_jjaf6

# Assignment 1: LSTM-based Stock Trading System
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt

from google.colab import drive
drive.mount('/content/drive')

import os

folder_path = '/content/drive/MyDrive/Sem 7/Advanced ML/sp500_tickers_A-D_1min_1pppix'
os.chdir(folder_path)

file_list = os.listdir()
print(file_list)  # Print the list of files in the folder

"""### a) Plot the minute-by-minute closing price series of few stocks"""

# List of stock symbols
stock_symbols = ['AAPL_1min','AON_1min', 'CHIR_1min', 'BA_1min']

# Create a figure and axis
fig, ax = plt.subplots(figsize=(20, 8))


# Iterate through each stock symbol and plot its closing price
for symbol in stock_symbols:
    file_name = f"{symbol}.txt"
    file_path = os.path.join(folder_path, file_name)

    if os.path.exists(file_path):
        df = pd.read_csv(file_path, header=None, names=['Timestamp', 'Open', 'High', 'Low', 'Close', 'Volume'])
        df['Timestamp'] = pd.to_datetime(df['Timestamp'], format='%Y-%m-%d %H:%M:%S', errors='coerce')  # Specify the format
        df = df.dropna(subset=['Timestamp'])

        # Set Timestamp as the index
        df.set_index('Timestamp', inplace=True)

        ax.plot(df.index, df['Close'], label=symbol)
# Set labels and title
ax.set_xlabel('Time')
ax.set_ylabel('Closing Price')
ax.set_title('Minute-by-Minute Closing Price of Stocks')


# Rotate x-axis labels for better readability
plt.xticks(rotation=45)

# Add legend
ax.legend()

# Display the plot
plt.tight_layout()
plt.show()


# https://www.kaggle.com/code/taronzakaryan/predicting-stock-price-using-lstm-model-pytorch
# ChatGPT for data reading and indexing
# https://github.com/Nils1511/EE769/blob/main/StockMarketAnalysis.ipynb

# Specific to one company
stock_symbols = ['AON_1min']

# Create a figure and axis
fig, ax = plt.subplots(figsize=(10, 6))
start_date = '2022-02-01'
#end_date = '2015-01-06'
# start_time = '09:30:00'
# end_time = '16:00:00'

# Iterate through each stock symbol and plot its closing price
for symbol in stock_symbols:
    file_name = f"{symbol}.txt"
    file_path = os.path.join(folder_path, file_name)

    if os.path.exists(file_path):
        df = pd.read_csv(file_path, header=None, names=['Timestamp', 'Open', 'High', 'Low', 'Close', 'Volume'])
        df['Timestamp'] = pd.to_datetime(df['Timestamp'], format='%Y-%m-%d %H:%M:%S')  # Specify the format

        # Set Timestamp as the index
        df.set_index('Timestamp', inplace=True)

        # Filter data within the specified date range
        df_filtered = df#[(df.index.date >= pd.to_datetime(start_date).date())]#&
                        #  (df.index.date <= pd.to_datetime(end_date).date())&
                        # (df.index.time > pd.to_datetime(start_time).time())&
                        # (df.index.time <= pd.to_datetime(end_time).time())]

        ax.plot(df_filtered.index, df_filtered['Close'], label=symbol)
# Set labels and title
ax.set_xlabel('Time')
ax.set_ylabel('Closing Price')
ax.set_title('Minute-by-Minute Closing Price of AON_1min')

# Rotate x-axis labels for better readability
plt.xticks(rotation=45)

# Add legend
ax.legend()

# Display the plot
plt.tight_layout()
plt.show()

# List of stock symbols
stock_symbols = ['AON_1min']

# Create a figure and axis
fig, ax = plt.subplots(figsize=(10, 6))
start_date = '2022-02-25'
#end_date = '2015-01-06'
start_time = '09:30:00'
end_time = '16:00:00'

# Iterate through each stock symbol and plot its closing price
for symbol in stock_symbols:
    file_name = f"{symbol}.txt"
    file_path = os.path.join(folder_path, file_name)

    if os.path.exists(file_path):
        df = pd.read_csv(file_path, header=None, names=['Timestamp', 'Open', 'High', 'Low', 'Close', 'Volume'])
        df['Timestamp'] = pd.to_datetime(df['Timestamp'], format='%Y-%m-%d %H:%M:%S')  # Specify the format

        # Set Timestamp as the index
        df.set_index('Timestamp', inplace=True)

        # Filter data within the specified date range
        df_filtered = df[(df.index.date >= pd.to_datetime(start_date).date())&
                        #  (df.index.date <= pd.to_datetime(end_date).date())&
                        (df.index.time > pd.to_datetime(start_time).time())&
                        (df.index.time <= pd.to_datetime(end_time).time())]

        ax.plot(df_filtered.index, df_filtered['Close'], label=symbol)
# Set labels and title
ax.set_xlabel('Time')
ax.set_ylabel('Closing Price')
ax.set_title('Minute-by-Minute Closing Price of AON_1min')

# Rotate x-axis labels for better readability
plt.xticks(rotation=45)

# Add legend
ax.legend()

# Display the plot
plt.tight_layout()
plt.show()

"""### b) Plot the day-by-day closing price series of a few stocks"""

stock_symbols = ['AON_1min']
# Create a figure and axis
fig, ax = plt.subplots(figsize=(10, 6))

# Iterate through each stock symbol and plot its day-by-day closing price
for symbol in stock_symbols:
    file_name = f"{symbol}.txt"
    file_path = os.path.join(folder_path, file_name)

    if os.path.exists(file_path):
        df = pd.read_csv(file_path, header=None, names=['Timestamp', 'Open', 'High', 'Low', 'Close', 'Volume'])
        df['Timestamp'] = pd.to_datetime(df['Timestamp'], format='%Y-%m-%d %H:%M:%S')  # Specify the format

        # Resample data to daily frequency and aggregate using mean (you can use other aggregation methods)
        df_resampled = df.resample('D', on='Timestamp').mean()

        ax.plot(df_resampled.index, df_resampled['Close'], label=symbol)

# Set labels and title
ax.set_xlabel('Date')
ax.set_ylabel('Closing Price')
ax.set_title('Day-by-Day Closing Price of Stocks')

# Rotate x-axis labels for better readability
plt.xticks(rotation=45)

# Add legend
ax.legend()

# Display the plot
plt.tight_layout()
plt.show()

# https://www.analyticsvidhya.com/blog/2018/10/predicting-stock-price-machine-learningnd-deep-learning-techniques-python/  + ChatGPT for mean of daily closing price

# For one company
stock_symbols = ['AON_1min']

# Create a figure and axis
start_date = '2022-01-01'
# end_date = '2015-06-12'
start_time = '09:30:00'
end_time = '16:00:00'

# Iterate through each stock symbol and plot its closing price
for symbol in stock_symbols:
    file_name = f"{symbol}.txt"
    file_path = os.path.join(folder_path, file_name)

    if os.path.exists(file_path):
        df = pd.read_csv(file_path, header=None, names=['Timestamp', 'Open', 'High', 'Low', 'Close', 'Volume'])
        df['Timestamp'] = pd.to_datetime(df['Timestamp'], format='%Y-%m-%d %H:%M:%S')  # Specify the format

        # Set Timestamp as the index
        df.set_index('Timestamp', inplace=True)

        # Filter data within the specified date range
        df_filtered = df[(df.index.date >= pd.to_datetime(start_date).date())&
                        #  (df.index.date <= pd.to_datetime(end_date).date())&
                        (df.index.time > pd.to_datetime(start_time).time())&
                        (df.index.time <= pd.to_datetime(end_time).time())]

        # Resample data to daily frequency and aggregate using mean (you can use other aggregation methods)
        # df_resampled = df_filtered.resample('D').mean()
        # Calculate the mean of the daily close prices
        daily_close_mean = df_filtered['Close'].resample('D').mean()

# Create a plot for the mean of daily close prices
plt.figure(figsize=(10, 6))
plt.plot(daily_close_mean.index, daily_close_mean, label='Mean Close Price', linewidth=1)
plt.title('Mean Daily Close Price')
plt.xlabel('Date')
plt.ylabel('Mean Close Price')
plt.grid(True)
plt.legend()
plt.xticks(rotation=45)
plt.tight_layout()
plt.show()

# For One company
stock_symbols = ['AON_1min']

# Create a figure and axis
fig, ax = plt.subplots(figsize=(10, 6))
start_date = '2015-01-05'
end_date = '2016-06-06'
start_time = '09:30:00'
end_time = '16:00:00'

# Iterate through each stock symbol and plot its closing price
for symbol in stock_symbols:
    file_name = f"{symbol}.txt"
    file_path = os.path.join(folder_path, file_name)

    if os.path.exists(file_path):
        df = pd.read_csv(file_path, header=None, names=['Timestamp', 'Open', 'High', 'Low', 'Close', 'Volume'])
        df['Timestamp'] = pd.to_datetime(df['Timestamp'], format='%Y-%m-%d %H:%M:%S')  # Specify the format

        # Set Timestamp as the index
        df.set_index('Timestamp', inplace=True)

        # Filter data within the specified date range
        df_filtered = df[(df.index.date >= pd.to_datetime(start_date).date())&
                         (df.index.date <= pd.to_datetime(end_date).date())&
                        (df.index.time > pd.to_datetime(start_time).time())&
                        (df.index.time <= pd.to_datetime(end_time).time())]

        daily_close_mean = df_filtered['Close'].resample('D').mean()

        ax.plot(daily_close_mean.index, daily_close_mean, label=symbol, color='red')
# Set labels and title
ax.set_xlabel('Time')
ax.set_ylabel('Closing Price')
ax.set_title('Minute-by-Minute Closing Price of AAP_1min')

# Rotate x-axis labels for better readability
plt.xticks(rotation=45)

# Add legend
ax.legend()

# Display the plot
plt.tight_layout()
plt.show()

"""### c) Plot a complete candlestick chart with volume on secondary y-axis for a few stocks with a time period of your choice"""

!pip install mplfinance
import mplfinance as mpf

stock_symbols = ['AON_1min' ]

# Define the date range for plotting
start_date = '2022-01-03'
end_date = '2022-01-04'

# Iterate through each stock symbol and plot its candlestick chart with volume
for symbol in stock_symbols:
    file_name = f"{symbol}.txt"
    file_path = os.path.join(folder_path, file_name)

    if os.path.exists(file_path):
        df = pd.read_csv(file_path, header=None, names=['Timestamp', 'Open', 'High', 'Low', 'Close', 'Volume'])
        df['Timestamp'] = pd.to_datetime(df['Timestamp'], format='%Y-%m-%d %H:%M:%S')  # Specify the format

        # Set Timestamp as the index
        df.set_index('Timestamp', inplace=True)

        # Filter data within the specified date range
        df_filtered =  df[(df.index.date >= pd.to_datetime(start_date).date()) &
                         (df.index.date <= pd.to_datetime(end_date).date()) ]
                        #  (df.index.time > pd.to_datetime(start_time).time()) &
                        #  (df.index.time <= pd.to_datetime(end_time).time())]

        if not df_filtered.empty:

            fig = mpf.figure(figsize=(10, 7))

            mpf.plot(df_filtered, type='candle', title=f'Candlestick Chart with Volume: {symbol}', ylabel='Price',
                     ylabel_lower='Volume', volume=True,style='charles', show_nontrading=False, returnfig=True)

            plt.show()  # Display the plot
        else:
            print(f"No data found for {symbol} in the specified range.")

# https://www.geeksforgeeks.org/plot-candlestick-chart-using-mplfinance-module-in-python/
# https://digitalcommons.odu.edu/cgi/viewcontent.cgi?article=1043&context=itds_facpubs

# Observe the features before 9:30

stock_symbols = ['AON_1min']

# Define the date range for plotting
start_date = '2022-01-03'  # Change to your desired start date
# end_date = '2015-01-06'    # Change to your desired end date
start_time = '09:30:00'
end_time = '10:30:00'
# Iterate through each stock symbol and plot its candlestick chart with volume
for symbol in stock_symbols:
    file_name = f"{symbol}.txt"
    file_path = os.path.join(folder_path, file_name)

    if os.path.exists(file_path):
        df = pd.read_csv(file_path, header=None, names=['Timestamp', 'Open', 'High', 'Low', 'Close', 'Volume'])
        df['Timestamp'] = pd.to_datetime(df['Timestamp'], format='%Y-%m-%d %H:%M:%S')  # Specify the format

        # Set Timestamp as the index
        df.set_index('Timestamp', inplace=True)

        # Filter data within the specified date range
        df_filtered = df[(df.index.date == pd.to_datetime(start_date).date()) &
                        #  (df.index.date <= pd.to_datetime(end_date).date())&
                        #  (df.index.time > pd.to_datetime(start_time).time()) &
                         (df.index.time < pd.to_datetime(end_time).time())]

        if not df_filtered.empty:
            plt.style.use('dark_background')
            fig = mpf.figure(figsize=(20, 7))
            mpf.plot(df_filtered, type='candle', title=f'Candlestick Chart with Volume: {symbol}', ylabel='Price',
                     ylabel_lower='Volume', volume=True, style='charles', show_nontrading=False, returnfig=True)

            plt.show()  # Display the plot
        else:
            print(f"No data found for {symbol} in the specified range.")

# Observe the features after 16:00

stock_symbols = ['AON_1min']
# Define the date range for plotting
start_date = '2022-01-05'
# end_date = '2015-01-06'
start_time = '15:30:00'
# end_time = '15:58:00'
# Iterate through each stock symbol and plot its candlestick chart with volume
for symbol in stock_symbols:
    file_name = f"{symbol}.txt"
    file_path = os.path.join(folder_path, file_name)

    if os.path.exists(file_path):
        df = pd.read_csv(file_path, header=None, names=['Timestamp', 'Open', 'High', 'Low', 'Close', 'Volume'])
        df['Timestamp'] = pd.to_datetime(df['Timestamp'], format='%Y-%m-%d %H:%M:%S')  # Specify the format

        # Set Timestamp as the index
        df.set_index('Timestamp', inplace=True)

        # Filter data within the specified date range
        df_filtered = df[(df.index.date == pd.to_datetime(start_date).date()) &
                        #  (df.index.date <= pd.to_datetime(end_date).date())]
                        (df.index.time > pd.to_datetime(start_time).time())]# &
                        #  (df.index.time <= pd.to_datetime(end_time).time())]

        if not df_filtered.empty:

            fig = mpf.figure(figsize=(20, 7))
            mpf.plot(df_filtered, type='candle', title=f'Candlestick Chart with Volume: {symbol}', ylabel='Price',
                     ylabel_lower='Volume', volume=True, style='charles', show_nontrading=False, returnfig=True)


            plt.show()  # Display the plot
        else:
            print(f"No data found for {symbol} in the specified range.")

stock_symbols = ['AON_1min' ]  # Update with your symbols

# Define the date range for plotting
start_date = '2015-01-04'  # Change to your desired start date
end_date = '2015-01-05'    # Change to your desired end date
start_time = '09:30:00'
end_time = '10:30:00'
# Iterate through each stock symbol and plot its candlestick chart with volume
for symbol in stock_symbols:
    file_name = f"{symbol}.txt"
    file_path = os.path.join(folder_path, file_name)

    if os.path.exists(file_path):
        df = pd.read_csv(file_path, header=None, names=['Timestamp', 'Open', 'High', 'Low', 'Close', 'Volume'])
        df['Timestamp'] = pd.to_datetime(df['Timestamp'], format='%Y-%m-%d %H:%M:%S')  # Specify the format

        # Set Timestamp as the index
        df.set_index('Timestamp', inplace=True)

        # Filter data within the specified date range
        df_filtered = df[(df.index.date >= pd.to_datetime(start_date).date()) &
                         (df.index.date <= pd.to_datetime(end_date).date()) &
                         (df.index.time > pd.to_datetime(start_time).time()) &
                         (df.index.time <= pd.to_datetime(end_time).time())]

        if not df_filtered.empty:
            # Plot candlestick chart with volume
            mc = mpf.make_marketcolors(up='g', down='r') #, edge='k', wick='k', ohlc='k')
            s = mpf.make_mpf_style(marketcolors=mc, gridstyle='--')

            fig, axes = mpf.plot(df_filtered, type='candle', title=f'Candlestick Chart with Volume: {symbol}', ylabel='Price',
                     ylabel_lower='Volume', volume=True,style=s, show_nontrading=False, returnfig=True)

            # Set the background color to black
            fig.patch.set_facecolor('black')
            axes[0].set_facecolor('black')
            axes[1].set_facecolor('black')
            # Set text colors to white
            for ax in axes:
                ax.tick_params(axis='y', colors='white')
                ax.tick_params(axis='x', colors='white')
                ax.yaxis.label.set_color('white')
                ax.xaxis.label.set_color('white')

            plt.show()  # Display the plot
        else:
            print(f"No data found for {symbol} in the specified range.")

"""### d) Note down your observations, e.g. are there any data issues, unexpected jumps, unexpected missing data etc.

Observtions:
      1. There is data present before 9:30:00 and after 16:00:00 time which is irrelevant for the training because it is present in very small volume and market
      is closed in that period so there is no movement in stock price.
      2. There is a some price jump on opening of market on next day as compared to previous day due to various factors or events occur in that time period.
      3. Some columns don't have data in the required format and also missing rows with minute by minute data.
      4. There are two days jump after the end of every week

### 2. Try at least two ways to normalize the data as stock prices and volumes change over time and are different across companies, and pick one by noting your justification.

Normalization is an important step when working with stock data, as it helps to bring different stocks' prices and volumes to a common scale, making them directly comparable. Here are two common ways to normalize the data: Min-Max Scaling and Z-Score Normalization.

1. Min-Max Scaling:
Min-Max Scaling scales the data to a specific range, usually between 0 and 1. It involves subtracting the minimum value from each data point and dividing by the range (maximum minus minimum). This method preserves the relationships between data points while transforming them to the desired range.

        Formula: normalized_value = (x - min(x)) / (max(x) - min(x))

2. Z-Score Normalization:
Z-Score Normalization (Standardization) transforms data by subtracting the mean and dividing by the standard deviation. This method centers the data around zero and scales it according to the standard deviation. Z-Score normalization is useful when you want to maintain a Gaussian distribution.

        Formula: normalized_value = (x - mean(x)) / std(x)
"""

from sklearn.preprocessing import StandardScaler, MinMaxScaler
stock_symbols = ['AON_1min' ]
start_time = '09:30:00'
end_time = '16:00:00'
# Iterate through each stock symbol and normalize the data
for symbol in stock_symbols:
    file_name = f"{symbol}.txt"
    file_path = os.path.join(folder_path, file_name)

    if os.path.exists(file_path):
        df = pd.read_csv(file_path, header=None, names=['Timestamp', 'Open', 'High', 'Low', 'Close', 'Volume'])
        df['Timestamp'] = pd.to_datetime(df['Timestamp'], format='%Y-%m-%d %H:%M:%S')  # Specify the format
        df.set_index('Timestamp', inplace=True)
        df_filtered = df[(df.index.time > pd.to_datetime(start_time).time()) &
                         (df.index.time <= pd.to_datetime(end_time).time())]
        # Normalize the 'Close' and 'Volume' columns using Z-Score
        scaler = StandardScaler()
        df_filtered[['Close']] = scaler.fit_transform(df_filtered[['Close']])
        df_filtered[['Volume']] = scaler.fit_transform(df_filtered[['Volume']])

df_filtered

stock_symbols = ['AON_1min' ]
start_time = '09:30:00'
end_time = '16:00:00'
# Iterate through each stock symbol and normalize the data
for symbol in stock_symbols:
    file_name = f"{symbol}.txt"
    file_path = os.path.join(folder_path, file_name)

    if os.path.exists(file_path):
        df = pd.read_csv(file_path, header=None, names=['Timestamp', 'Open', 'High', 'Low', 'Close', 'Volume'])
        df['Timestamp'] = pd.to_datetime(df['Timestamp'], format='%Y-%m-%d %H:%M:%S')  # Specify the format
        df.set_index('Timestamp', inplace=True)
        df_filtered = df[(df.index.time > pd.to_datetime(start_time).time()) &
                         (df.index.time <= pd.to_datetime(end_time).time())]
        # Normalize the 'Close' and 'Volume' columns using MinMaxScaling
        scaler = MinMaxScaler()
        df_filtered[['Close']] = scaler.fit_transform(df_filtered[['Close']])
        df_filtered[['Volume']] = scaler.fit_transform(df_filtered[['Volume']])

df_filtered

"""Justification:

Both Min-Max Scaling and Z-Score Normalization are valid methods for normalizing data. However, for financial data like stock prices and volumes, where outliers can have a significant impact on the data distribution, Z-Score Normalization might be more suitable. Z-Score normalization takes into account the data's mean and standard deviation, which can help mitigate the effects of outliers and extreme values.

Stock prices and volumes can be affected by unexpected events, leading to occasional spikes or drops that can skew the data. Z-Score normalization adjusts the data relative to the mean and standard deviation, making it robust to outliers and better suited to financial data.

### 3. Some Decisions:

a) high-frequency trading or intra-day swing, or inter-day trade, or long-term (multi-day ormulti-week or multi-month).

     For this scenario, let's consider "Intra-day Swing Trading." Intra-day swing trading involves capturing short to medium-term price movements
     within a single trading day. This approach takes advantage of price fluctuations that occur during the trading hours.

b) Assume a buy-ask spread (inversely related to volume and directly related to price) and trade commission based on a quick market research. Your trade will lose the buy-ask spread and commissions every time you trade

    Buy-ask spread of 0.05% of the stock price and a fixed commission of $5 per trade. Keep in mind that these
    values are approximate and can vary depending on the stock, broker, and market conditions.

c) Decide if you will trade only one stock, or have a model to trade a basket from a particularindustry, or any stock.

    Focusing on a particular industry, like the technology sector, provides the advantage of specialized knowledge about the industry's trends,
    news, and events. It also allows us to benefit from correlation among stocks within the same sector. However, it's essential to stay updated
    with industry-specific news and events that can affect your trading decisions.

    But I will trade only on one stock due to complexity of model.

### 4. Write a pytorch module for defining an LSTM model. Keep it flexible so that the input dimension, number of units, number of layers can easily be changed.
"""

import torch
import torch.nn as nn

class LSTM_Model(nn.Module):
    def __init__(self, input_dim, hidden_dim, layer_num, output_dim):
        super(LSTM_Model, self).__init__()

        self.hidden_dim = hidden_dim
        self.layer_num = layer_num

        self.lstm = nn.LSTM(input_dim, hidden_dim, layer_num, batch_first=True)
        self.fc = nn.Linear(hidden_dim, output_dim)

    def forward(self, x):
        h0 = torch.zeros(self.layer_num, x.size(0), self.hidden_dim).to(x.device)
        c0 = torch.zeros(self.layer_num, x.size(0), self.hidden_dim).to(x.device)

        out, _ = self.lstm(x, (h0, c0))
        out = self.fc(out[:, -1, :])
        return out

# Define hyperparameters
input_dim = 10
hidden_dim = 50
num_layers = 2
output_dim = 1

# Create an instance of the LSTM model
model = LSTM_Model(input_dim, hidden_dim, num_layers, output_dim)

# Print the model architecture
print(model)


# https://www.kaggle.com/code/taronzakaryan/predicting-stock-price-using-lstm-model-pytorch
# https://towardsdatascience.com/lstm-time-series-forecasting-predicting-stock-prices-using-an-lstm-model-6223e9644a2f

"""### 5. Write a flexible dataloader for training the LSTM model, especially if you are high frequency data. The inputs should be open, close, high, low, volume of one or more stocks (e.g. other stocks that canhelp predict the chosen stock price)."""

import torch
from torch.utils.data import Dataset, DataLoader
from sklearn.preprocessing import StandardScaler, MinMaxScaler

# Create a custom dataset class
class StockDataset(Dataset):
    def __init__(self, data, sequence_length, prediction_horizon=0):
        self.data = data
        self.sequence_length = sequence_length
        self.prediction_horizon = prediction_horizon
    def __len__(self):
        return len(self.data) - self.sequence_length - self.prediction_horizon + 1

    def __getitem__(self, idx):
        x = self.data[idx:idx + self.sequence_length]
        y_idx = idx + self.sequence_length - 1 + self.prediction_horizon
        y = torch.FloatTensor([self.data[y_idx]])
        return x, y

# Define your list of stock symbols (e.g., ['AAL_1min', 'AAPL_1min', ...])
stock_symbols = ['AON_1min']  # Add more as needed

# Initialize train and test data dictionaries for each stock symbol
train_data = {}
test_data = {}

# Define sequence length and batch size
sequence_length = 1
batch_size = 64
prediction_horizon = 1
# Filter data within the last 5 years
start_time = '09:30:00'
end_time = '16:00:00'
start_date = '2016-01-01'

# Load and preprocess data for each stock symbol
for symbol in stock_symbols:
    file_name = f"{symbol}.txt"
    file_path = os.path.join(folder_path, file_name)

    if os.path.exists(file_path):
        # Load data from the CSV file
        df = pd.read_csv(file_path, header=None, names=['Timestamp', 'Open', 'High', 'Low', 'Close', 'Volume'])
        df['Timestamp'] = pd.to_datetime(df['Timestamp'], format='%Y-%m-%d %H:%M:%S', errors='coerce')  # Specify the format
        df = df.dropna(subset=['Timestamp'])
        # Set Timestamp as the index
        df.set_index('Timestamp', inplace=True)

        # Filter data within the specified date and time range
        df_filtered = df[(df.index.date >= pd.to_datetime(start_date).date()) &
                          (df.index.time >= pd.to_datetime(start_time).time()) &
                          (df.index.time <= pd.to_datetime(end_time).time())]

        # Normalize the data using Min-Max scaling
        scaler = StandardScaler()
        df_filtered[['Open', 'High', 'Low', 'Close', 'Volume']] = scaler.fit_transform(
            df_filtered[['Open', 'High', 'Low', 'Close', 'Volume']])

        # Split data into train and test (leave the last two years for testing)
        split_point = -2 * 252 * 400  # Two years of minutes data
        train_df = df_filtered.iloc[:split_point]
        test_df = df_filtered.iloc[split_point:]

        # Store 'Close' prices as the target data
        train_data[symbol] = train_df['Close'].values
        test_data[symbol] = test_df['Close'].values

# Create the StockDataset and DataLoader for each stock symbol
train_dataloaders = {}
for symbol, data in train_data.items():
    stock_dataset = StockDataset(data=data, sequence_length=sequence_length,prediction_horizon=5)
    train_dataloaders[symbol] = DataLoader(stock_dataset, batch_size=batch_size, shuffle=False)

# https://www.kaggle.com/code/taronzakaryan/predicting-stock-price-using-lstm-model-pytorch
# https://towardsdatascience.com/lstm-time-series-forecasting-predicting-stock-prices-using-an-lstm-model-6223e9644a2f

train_df

test_df

"""### 6. Train or pre-train the model by trying to predict the future price (or change in price, if normalized) and keep the future horizon flexible (e.g., easy to change between one minute or 10 minutes into the future). You can try to predict the opening or closing time. Leave the last two years out for testing."""

import torch
import torch.nn as nn
import torch.optim as optim  # Import the optimizer module
from torch.utils.data import Dataset, DataLoader
from sklearn.preprocessing import StandardScaler
import pandas as pd
import numpy as np
import os
import argparse
from torch.cuda.amp import autocast, GradScaler

# Initialize the model and optimizer
input_dim = 1  # Assuming you are using only the 'Close' price as input
hidden_dim = 4
layer_num = 3
output_dim = 1  # Predicting the next 'Close' price
model = LSTM_Model(input_dim, hidden_dim, layer_num, output_dim).float()
optimizer = torch.optim.Adam(model.parameters(), lr=0.001)
criterion = nn.MSELoss()

# Training loop
num_epochs = 50
y_true = []
y_pred = []
for epoch in range(num_epochs):
    total_loss = 0.0
    model.train()

    for symbol, dataloader in train_dataloaders.items():
        for input, target in dataloader:
            optimizer.zero_grad()

            input = input.unsqueeze(-1).float()
            target = target.float()

            output = model(input)

            if epoch==num_epochs-1:
              y_true.append(target)
              y_pred.append(output)
            loss = criterion(output, target)
            loss.backward()
            optimizer.step()

            total_loss += loss.item()

    average_loss = total_loss / len(train_dataloaders)
    print(f'Epoch [{epoch + 1}/{num_epochs}], Loss: {average_loss:.4f}')# Initialize the model and optimizer

# Save the trained model
torch.save(model.state_dict(), 'lstm_model.pth')

# https://www.kaggle.com/code/taronzakaryan/predicting-stock-price-using-lstm-model-pytorch
# https://towardsdatascience.com/lstm-time-series-forecasting-predicting-stock-prices-using-an-lstm-model-6223e9644a2f
# ChatGPT + Bard

"""### 7. Set up a trading module that will make some hard-coded logical decisions to buy, hold, sell (in any order, because in shorting you can sell first and buy later)."""

class TradingModule:
    def __init__(self, model, scaler, buy_threshold, sell_threshold):
        self.model = model
        self.scaler = scaler
        self.buy_threshold = buy_threshold  # Define your buy threshold
        self.sell_threshold = sell_threshold  # Define your sell threshold
        self.holding = False
        self.holding_price = 0.0

    def normalize_data(self, data):
        # Inverse transform to get original price
        return self.scaler.inverse_transform(data.reshape(1, -1))  # Assuming 'Close' price is at index 3

    def decide_trade(self, current_price, predicted_price):
        if not self.holding:
            # If not holding, check if you should buy
            if predicted_price < (1 + self.buy_threshold) * current_price:
                self.holding = True
                self.holding_price = current_price
                return "Buy"
        else:
            # If holding, check if you should sell
            if predicted_price > (1 - self.sell_threshold) * self.holding_price:
                self.holding = False
                return "Sell"

        # If not buying or selling, hold
        return "Hold"


# Logic from ChatGpt + Bard

"""### 8. Test the trading system on the latest years on which the model was not trained.

a) Does the price prediction error increase as you go further from the last time on which it was trained?
"""

model.eval()  # Set the model to evaluation mode
with torch.no_grad():
    for symbol, data in test_data.items():

        test_dataset = StockDataset(data=data, sequence_length=sequence_length)
        test_dataloader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)

        for inputs, target in test_dataloader:
            inputs = inputs.unsqueeze(-1).float()
            target = target.float()
            # Forward pass
            outputs = model(inputs)

            # Get the predicted price for the future time step
            predicted_price = outputs[0].item()

            # Get the current price (last observed closing price)
            current_price = inputs[0].item()

            print(current_price,predicted_price)

# Initialize a list to store MSE values
mse_values = []
forecast_horizon=20

# Testing loop (for one company, repeat for each company)
model.eval()  # Set the model to evaluation mode
with torch.no_grad():
    for symbol, data in test_data.items():

        test_dataset = StockDataset(data=data, sequence_length=sequence_length, prediction_horizon=10)
        test_dataloader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)

        for inputs, future_targets in test_dataloader:
            inputs = inputs.unsqueeze(-1).float()
            future_targets = future_targets.float()
            # Forward pass
            outputs = model(inputs)

            # Compute the Mean Squared Error (MSE)
            mse = criterion(outputs, future_targets)
            mse_values.append(mse.item())

# We have list of MSE values, plot them against time steps to observe how the error changes over time.
plt.figure(figsize=(12, 6))
plt.plot(range(len(mse_values)), mse_values, label='MSE', color='blue')
plt.title('Mean Squared Error (MSE) Over Time')
plt.xlabel('Time Steps')
plt.ylabel('MSE Value')
plt.legend()
plt.grid(True)
plt.show()

"""***Yes, the prediction error increases as we go further from the last time on which it was trained.***

b) Can you profitably trade with the bid-ask spread and commissions taken into account?
"""

buy_threshold = 0.0002  # Define your buy threshold (e.g., 0.002% increase)
sell_threshold = 0.0001  # Define your sell threshold (e.g., 0.001% decrease)

bid_ask_spread = 0.01  # Bid-ask spread as a percentage (e.g., 1%)
commission_rate = 0.005  # Commission rate as a percentage (e.g., 0.5%)

# Define trading parameters (adjust as needed)
initial_cash = 10000  # Initial cash (e.g., $10,000)
initial_holdings = 0  # Initial holdings
bid_ask_spread = 0.01  # Bid-ask spread as a percentage (e.g., 1%)
commission_rate = 0.005  # Commission rate as a percentage (e.g., 0.5%)

# Initialize portfolio variables
cash = initial_cash
holdings = initial_holdings

# List to track trade actions and their timestamps
trade_log = []

# Initialize the trading module with your LSTM model and scaler
trading_module = TradingModule(model, scaler, buy_threshold, sell_threshold)

model.eval()  # Set the model to evaluation mode
with torch.no_grad():
    for symbol, data in test_data.items():

        test_dataset = StockDataset(data=data, sequence_length=sequence_length)
        test_dataloader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)

        # holdings = 0.0  # Initial holdings
        # cash = 100000.0  # Initial cash
        count = 0
        for inputs, target in test_dataloader:
            inputs = inputs.unsqueeze(-1).float()
            target = target.float()
            # Forward pass
            outputs = model(inputs)

            # Get the predicted price for the future time step
            predicted_price = outputs[0].item()

            # Get the current price (last observed closing price)
            current_price = inputs[0].item()

            # Make a trading decision
            decision = trading_module.decide_trade(current_price, predicted_price)
            print(current_price,predicted_price)
            # Execute trading logic based on the decision (in this example, print the decision)

            # Calculate bid-ask spread and commissions
            ask_price = current_price * (1 + bid_ask_spread / 100)
            bid_price = current_price * (1 - bid_ask_spread / 100)
            commission = commission_rate * abs(holdings) * current_price


            if decision == "Buy" and cash >= ask_price:
                # Buy logic
                shares_bought = cash / ask_price
                cash -= shares_bought * ask_price  # Deduct the cost of shares and commission
                holdings += shares_bought
                cash -= commission
                trade_log.append((symbol, "Buy", current_price, shares_bought))
                print(f"Buy at {current_price:.2f}")
            elif decision == "Sell" and holdings > 0:
                # Sell logic
                cash_from_sale = holdings * bid_price
                cash -= commission  # Deduct the commission
                cash += cash_from_sale  # Add the cash from the sale
                holdings = 0
                trade_log.append((symbol, "Sell", current_price, holdings))
                print(f"Sell at {current_price:.2f}")

            count = count + 1
            if count == 30:
               break


# Calculate and print the final portfolio value
final_portfolio_value = cash + holdings * current_price
print(f"Final Portfolio Value: ${final_portfolio_value:.2f}")

# # Analyze trade log to calculate total trades, profits, losses, etc.
# Create a DataFrame from the trade log
trade_df = pd.DataFrame(trade_log, columns=['Symbol', 'Action', 'Price', 'Quantity'])

# Calculate total trades
total_trades = len(trade_df)


if final_portfolio_value > initial_cash:
    profit = final_portfolio_value - initial_cash
elif final_portfolio_value < initial_cash:
  loss = final_portfolio_value - initial_cash

# Print trading statistics
print(f"Total Trades: {total_trades}")
print(f"Total Profits: ${profit:.2f}")
print(f"Total Losses: ${loss:.2f}")


# https://www.activestate.com/blog/how-to-build-an-algorithmic-trading-bot/

"""# ***Yes, But not satisfactory, I might be able to profitably trade if I increase the prediction horizon of the model because i got prediction price much close to current price.***

c) How does your profitability compare to a simple buy-and-hold strategy over long term (e.g.one or two years)?
"""

buy_threshold = 0.0002  # Define your buy threshold (e.g., 0.002% increase)
sell_threshold = 0.0001  # Define your sell threshold (e.g., 0.001% decrease)

bid_ask_spread = 0.01  # Bid-ask spread as a percentage (e.g., 1%)
commission_rate = 0.005  # Commission rate as a percentage (e.g., 0.5%)

# Define trading parameters (adjust as needed)
initial_cash = 10000  # Initial cash (e.g., $10,000)
initial_holdings = 0  # Initial holdings
bid_ask_spread = 0.01  # Bid-ask spread as a percentage (e.g., 1%)
commission_rate = 0.005  # Commission rate as a percentage (e.g., 0.5%)

# Initialize portfolio variables
cash = initial_cash
holdings = initial_holdings

# List to track trade actions and their timestamps
trade_log = []

# Initialize the trading module with your LSTM model and scaler
trading_module = TradingModule(model, scaler, buy_threshold, sell_threshold)

model.eval()  # Set the model to evaluation mode
with torch.no_grad():
    for symbol, data in test_data.items():

        test_dataset = StockDataset(data=data, sequence_length=sequence_length)
        test_dataloader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)

        # holdings = 0.0  # Initial holdings
        # cash = 100000.0  # Initial cash
        # count = 0
        for inputs, target in test_dataloader:
            inputs = inputs.unsqueeze(-1).float()
            target = target.float()
            # Forward pass
            outputs = model(inputs)

            # Get the predicted price for the future time step
            predicted_price = outputs[0].item()

            # Get the current price (last observed closing price)
            current_price = inputs[0].item()

            # Make a trading decision
            decision = trading_module.decide_trade(current_price, predicted_price)
            # print(current_price,predicted_price)
            # Execute trading logic based on the decision (in this example, print the decision)

            # Calculate bid-ask spread and commissions
            ask_price = current_price * (1 + bid_ask_spread / 100)
            bid_price = current_price * (1 - bid_ask_spread / 100)
            commission = commission_rate * abs(holdings) * current_price


            if decision == "Buy" and cash >= ask_price:
                # Buy logic
                shares_bought = cash / ask_price
                cash -= shares_bought * ask_price  # Deduct the cost of shares and commission
                holdings += shares_bought
                cash -= commission
                trade_log.append((symbol, "Buy", current_price, shares_bought))
                print(f"Buy at {current_price:.2f}")
            elif decision == "Sell" and holdings > 0:
                # Sell logic
                cash_from_sale = holdings * bid_price
                cash -= commission  # Deduct the commission
                cash += cash_from_sale  # Add the cash from the sale
                holdings = 0
                trade_log.append((symbol, "Sell", current_price, holdings))
                print(f"Sell at {current_price:.2f}")

            # count = count + 1
            # if count == 30:
            #    break


# Calculate and print the final portfolio value
final_portfolio_value = cash + holdings * current_price
print(f"Final Portfolio Value: ${final_portfolio_value:.2f}")

# # Analyze trade log to calculate total trades, profits, losses, etc.
# Create a DataFrame from the trade log
trade_df = pd.DataFrame(trade_log, columns=['Symbol', 'Action', 'Price', 'Quantity'])

# Calculate total trades
total_trades = len(trade_df)


if final_portfolio_value > initial_cash:
    profit = final_portfolio_value - initial_cash
elif final_portfolio_value < initial_cash:
  loss = final_portfolio_value - initial_cash

# Print trading statistics
print(f"Total Trades: {total_trades}")
print(f"Total Profits: ${profit:.2f}")
print(f"Total Losses: ${loss:.2f}")

"""***If i buy and hold some stock for a long term the profit margin is huge as compared to my profitability.***

### 9. Advanced:

  a) Can you now modify the model to use multiple stock prices as inputs to predict a single stock (your choice)? Does it improve predictions?

 b) Can you add day of the week, day in year, and time as inputs? Does it improve results?
"""

import torch
from torch.utils.data import Dataset, DataLoader
from sklearn.preprocessing import StandardScaler, MinMaxScaler

# Create a custom dataset class
class ReStockDataset(Dataset):
    def __init__(self, data, target, sequence_length, prediction_horizon=0):
        self.data = data
        self.target = target
        self.sequence_length = sequence_length
        self.prediction_horizon = prediction_horizon
    def __len__(self):
        return len(self.data) - self.sequence_length - self.prediction_horizon + 1

    def __getitem__(self, idx):
        x = self.data[idx:idx + self.sequence_length]
        y_idx = idx + self.sequence_length - 1 + self.prediction_horizon
        y = torch.FloatTensor([self.target[y_idx]])
        return x, y


# Define your list of stock symbols (e.g., ['AAL_1min', 'AAPL_1min', ...])
stock_symbols = ['AON_1min']  # Add more as needed

# Initialize train and test data dictionaries for each stock symbol
train_data = {}
test_data = {}

# Define sequence length and batch size
sequence_length = 1
batch_size = 160

# Filter data within the last 5 years
start_time = '09:30:00'
end_time = '16:00:00'
start_date = '2016-01-01'
# Load and preprocess data for each stock symbol
for symbol in stock_symbols:
    file_name = f"{symbol}.txt"
    file_path = os.path.join(folder_path, file_name)

    if os.path.exists(file_path):
        # Load data from the CSV file
        df = pd.read_csv(file_path, header=None, names=['Timestamp', 'Open', 'High', 'Low', 'Close', 'Volume'])
        df['Timestamp'] = pd.to_datetime(df['Timestamp'], format='%Y-%m-%d %H:%M:%S', errors='coerce')  # Specify the format
        df = df.dropna(subset=['Timestamp'])
        # Set Timestamp as the index
        df.set_index('Timestamp', inplace=True)

        # Filter data within the specified date range
        df_filtered = df[(df.index.date >= pd.to_datetime(start_date).date())&
                          # (df.index.date <= pd.to_datetime(end_date).date())&
                          (df.index.time > pd.to_datetime(start_time).time())&
                          (df.index.time <= pd.to_datetime(end_time).time())]

        # Normalize the data using StandardScaler
        scaler = StandardScaler()
        df_filtered[['Open', 'High', 'Low', 'Close', 'Volume']] = scaler.fit_transform(df_filtered[['Open', 'High', 'Low', 'Close', 'Volume']])

        # Split data into train and test (leave the last two years for testing)
        split_point = -2 * 252 * 400  # Two years of minutes data
        train_df = df_filtered.iloc[:split_point]
        test_df = df_filtered.iloc[split_point:]

        # Convert data to numpy arrays
        train_data[symbol] = train_df[['Open', 'High', 'Low', 'Close', 'Volume']].to_numpy()
        test_data[symbol] = test_df[['Open', 'High', 'Low', 'Close', 'Volume']].to_numpy()

# Create the StockDataset and DataLoader for each stock symbol
train_dataloaders = {}
for symbol, data in train_data.items():
    target = data[:, 3]  # Assuming want to predict the closing price
    stock_dataset = ReStockDataset(data=data, target=target, sequence_length=sequence_length, prediction_horizon=400)
    train_dataloaders[symbol] = DataLoader(stock_dataset, batch_size=batch_size, shuffle=True)

import os
import numpy as np
import pandas as pd
import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import Dataset, DataLoader
from sklearn.preprocessing import StandardScaler
from torch.cuda.amp import autocast, GradScaler
# Define the LSTM model with mixed precision training
class LSTM_Model(nn.Module):
    def __init__(self, input_dim, hidden_dim, num_layers, output_dim, dropout=0.0):
        super(LSTM_Model, self).__init__()

        self.hidden_dim = hidden_dim
        self.num_layers = num_layers

        # Define the LSTM layer
        self.lstm = nn.LSTM(input_dim, hidden_dim, num_layers, batch_first=True, dropout=dropout)

        # Define the output layer
        self.fc = nn.Linear(hidden_dim, output_dim)

    def forward(self, x):
        # Initialize hidden state with zeros
        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_dim).double()

        # Initialize cell state
        c0 = torch.zeros(self.num_layers, x.size(0), self.hidden_dim).double()

        # We need to detach as we are doing truncated backpropagation through time (BPTT)
        # If we don't, we'll backprop all the way to the start even after going through another batch
        out, (hn, cn) = self.lstm(x, (h0.detach(), c0.detach()))

        # Index hidden state of the last time step
        out = self.fc(out[:, -1, :])

        return out

# Initialize the model
model = LSTM_Model(input_dim=5, hidden_dim=16, num_layers=4, output_dim=1, dropout=0.0)
model = model.double()  # Set the model to use double precision

# Define the loss criterion (e.g., Mean Squared Error) and optimizer
criterion = nn.MSELoss()
optimizer = optim.Adam(model.parameters(), lr=0.01)


# Training loop (for one company, repeat for each company)
forecast_horizon = 10  # Adjust the forecast horizon (e.g., 1 for one minute or 10 for ten minutes into the future)
num_epochs = 10

for epoch in range(num_epochs):
    for symbol, dataloader in train_dataloaders.items():
        model.train()  # Set the model to training mode
        for inputs, targets in dataloader:
            # Create a target for the future time step
            inputs = inputs.to(torch.double)

            # Predict closing price
            targets = targets.double()

            # Zero the parameter gradients
            optimizer.zero_grad()

            # Forward pass
            outputs = model(inputs)  # Adjust inputs as needed

            # Compute the loss
            loss = criterion(outputs, targets)  # Adjust targets as needed

            # Backpropagation and optimization
            loss.backward()
            optimizer.step()

            # Print training statistics
print(f'Epoch [{epoch + 1}/{num_epochs}], Loss: {loss.item():.4f} (Symbol: {symbol})')





https://link.springer.com/article/10.1007/s12530-022-09481-x
https://link.springer.com/article/10.1007/s11135-022-01605-4
https://journalofbigdata.springeropen.com/articles/10.1186/s40537-022-00597-0
https://www.kaggle.com/code/taronzakaryan/predicting-stock-price-using-lstm-model-pytorch
https://www.kaggle.com/code/taronzakaryan/predicting-stock-price-using-lstm-model-pytorch
https://github.com/Nils1511/EE769/blob/main/StockMarketAnalysis.ipynb